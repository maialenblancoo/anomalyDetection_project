{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. Directory setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "notebook_dir = os.getcwd()\n",
        "\n",
        "project_dir = notebook_dir\n",
        "if os.path.basename(notebook_dir) == 'notebooks':\n",
        "    project_dir = os.path.dirname(notebook_dir)\n",
        "    os.chdir(project_dir)\n",
        "\n",
        "if project_dir not in sys.path:\n",
        "    sys.path.insert(0, project_dir)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZUT3EtJX8SF"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "from utils.data_loader import load_data, load_anomaly_labels, normalize_data, create_sequences\n",
        "from utils.data_loader import create_labels_array, split_data, prepare_data_loaders\n",
        "from utils.model_utils import LSTMAutoencoder, GRUAutoencoder, TransformerEncoder, train_model\n",
        "from utils.model_utils import get_reconstruction_errors, EnsembleModel, save_trained_models\n",
        "from utils.evaluation import evaluate_threshold, AnomalyInterpreter, visualize_results\n",
        "from utils.evaluation import plot_roc_curves, plot_precision_recall_curves, create_results_summary, print_results_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Initial Configuration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"notebook\", font_scale=1.2)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "logger.info(f\"Usando dispositivo: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load and prepare data\n",
        "filepath = 'data/machine_temperature_system_failure.csv'\n",
        "labels_path = 'data/known_labels_v1.0.json'\n",
        "windows_path = 'data/combined_windows.json'\n",
        "\n",
        "df = load_data(filepath)\n",
        "labels_dict, windows_dict = load_anomaly_labels(labels_path, windows_path)\n",
        "\n",
        "filename = 'realKnownCause/machine_temperature_system_failure.csv'\n",
        "anomaly_timestamps = labels_dict[filename]\n",
        "anomaly_windows = windows_dict[filename]\n",
        "\n",
        "data_scaled, scaler = normalize_data(df[['value']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "sequence_length = 150\n",
        "step = 10\n",
        "\n",
        "X = create_sequences(data_scaled, sequence_length, step)\n",
        "y = create_labels_array(df, anomaly_timestamps, anomaly_windows, sequence_length, step)\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = prepare_data_loaders(X_train, X_val, X_test, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Construct Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Train models\n",
        "lstm_autoencoder = LSTMAutoencoder(seq_len=sequence_length, n_features=1, embedding_dim=64, dropout=0.2)\n",
        "gru_autoencoder = GRUAutoencoder(seq_len=sequence_length, n_features=1, embedding_dim=64, dropout=0.2)\n",
        "transformer_model = TransformerEncoder(seq_len=sequence_length, n_features=1, d_model=48, nhead=4,\n",
        "                                       dropout=0.3, num_layers=2)\n",
        "\n",
        "lstm_history, lstm_model = train_model(\n",
        "    lstm_autoencoder, train_loader, val_loader, n_epochs=50, learning_rate=1e-3,\n",
        "    device=device, patience=7, min_delta=0.0001, weight_decay=1e-5\n",
        ")\n",
        "\n",
        "gru_history, gru_model = train_model(\n",
        "    gru_autoencoder, train_loader, val_loader, n_epochs=50, learning_rate=1e-3,\n",
        "    device=device, patience=7, min_delta=0.0001, weight_decay=1e-5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Pre-train Transformer model on normal data only\n",
        "normal_mask = y_train == 0\n",
        "X_normal = torch.FloatTensor(X_train[normal_mask])\n",
        "normal_dataset = torch.utils.data.TensorDataset(X_normal)\n",
        "normal_loader = torch.utils.data.DataLoader(normal_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "transformer_model = transformer_model.to(device)\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    transformer_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in normal_loader:\n",
        "        seq_true = batch[0].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        seq_pred = transformer_model(seq_true)\n",
        "        loss = criterion(seq_pred, seq_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    logger.info(f\"Transformer Pretraining Epoch {epoch+1}/20, Loss: {total_loss/len(normal_loader):.5f}\")\n",
        "\n",
        "transformer_history, transformer_model = train_model(\n",
        "    transformer_model, train_loader, val_loader, n_epochs=50, learning_rate=1e-3,\n",
        "    device=device, patience=7, min_delta=0.0001, weight_decay=1e-5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Get reconstruction errors\n",
        "lstm_errors, lstm_orig, lstm_recon = get_reconstruction_errors(lstm_model, test_loader, device)\n",
        "gru_errors, gru_orig, gru_recon = get_reconstruction_errors(gru_model, test_loader, device)\n",
        "transformer_errors, transformer_orig, transformer_recon = get_reconstruction_errors(transformer_model, test_loader, device)\n",
        "\n",
        "val_lstm_errors, _, _ = get_reconstruction_errors(lstm_model, val_loader, device)\n",
        "val_gru_errors, _, _ = get_reconstruction_errors(gru_model, val_loader, device)\n",
        "val_transformer_errors, _, _ = get_reconstruction_errors(transformer_model, val_loader, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create ensemble model\n",
        "ensemble = EnsembleModel(\n",
        "    models=[lstm_model, gru_model, transformer_model],\n",
        "    names=[\"LSTM\", \"GRU\", \"Transformer\"]\n",
        ")\n",
        "\n",
        "ensemble.optimize_weights(\n",
        "    [val_lstm_errors, val_gru_errors, val_transformer_errors],\n",
        "    y_val\n",
        ")\n",
        "\n",
        "ensemble_errors, individual_errors = ensemble.get_weighted_errors(\n",
        "    [test_loader, test_loader, test_loader],\n",
        "    device\n",
        ")\n",
        "\n",
        "val_ensemble_errors, _ = ensemble.get_weighted_errors(\n",
        "    [val_loader, val_loader, val_loader],\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate models\n",
        "lstm_results = evaluate_threshold(lstm_errors, y_test, val_lstm_errors, factor=1.5)\n",
        "gru_results = evaluate_threshold(gru_errors, y_test, val_gru_errors, factor=1.5)\n",
        "transformer_results = evaluate_threshold(transformer_errors, y_test, val_transformer_errors, factor=1.5)\n",
        "ensemble_results = evaluate_threshold(ensemble_errors, y_test, val_ensemble_errors, factor=1.5)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n=== Results with Adaptive Threshold (factor 1.5) ===\")\n",
        "results_summary = {\n",
        "    'lstm': lstm_results,\n",
        "    'gru': gru_results,\n",
        "    'transformer': transformer_results,\n",
        "    'ensemble': ensemble_results\n",
        "}\n",
        "print_results_table(create_results_summary({\n",
        "    'results': results_summary,\n",
        "    'thresholds': {\n",
        "        'lstm': lstm_results['threshold'],\n",
        "        'gru': gru_results['threshold'],\n",
        "        'transformer': transformer_results['threshold'],\n",
        "        'ensemble': ensemble_results['threshold']\n",
        "    }\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Interpret and Analyze Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create interpreter\n",
        "timestamps = df.index[sequence_length:][::step][-len(ensemble_errors):]\n",
        "interpreter = AnomalyInterpreter(\n",
        "    model=None,\n",
        "    test_data=lstm_orig,\n",
        "    reconstructed_data=lstm_recon,\n",
        "    errors=ensemble_errors,\n",
        "    thresholds=ensemble_results['threshold'],\n",
        "    timestamps=timestamps\n",
        ")\n",
        "\n",
        "# Analyze top anomalies\n",
        "top_anomalies = interpreter.analyze_top_anomalies(top_k=5)\n",
        "print(\"\\n=== Top 5 Detected Anomalies ===\")\n",
        "for i, anomaly in enumerate(top_anomalies):\n",
        "    print(f\"Anomaly #{i+1}:\")\n",
        "    print(f\"  Index: {anomaly['index']}\")\n",
        "    if 'timestamp' in anomaly:\n",
        "        print(f\"  Timestamp: {anomaly['timestamp']}\")\n",
        "    print(f\"  Error: {anomaly['error']:.6f}\")\n",
        "    print(f\"  Threshold: {anomaly['threshold']:.6f}\")\n",
        "    print(f\"  Error/Threshold Ratio: {anomaly['error_ratio']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Prepare results dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Prepare results dictionary\n",
        "results_dict = {\n",
        "    'models': {\n",
        "        'lstm': lstm_model,\n",
        "        'gru': gru_model,\n",
        "        'transformer': transformer_model,\n",
        "        'ensemble': ensemble\n",
        "    },\n",
        "    'errors': {\n",
        "        'lstm': lstm_errors,\n",
        "        'gru': gru_errors,\n",
        "        'transformer': transformer_errors,\n",
        "        'ensemble': ensemble_errors\n",
        "    },\n",
        "    'thresholds': {\n",
        "        'lstm': lstm_results['threshold'],\n",
        "        'gru': gru_results['threshold'],\n",
        "        'transformer': transformer_results['threshold'],\n",
        "        'ensemble': ensemble_results['threshold']\n",
        "    },\n",
        "    'results': {\n",
        "        'lstm': lstm_results,\n",
        "        'gru': gru_results,\n",
        "        'transformer': transformer_results,\n",
        "        'ensemble': ensemble_results\n",
        "    },\n",
        "    'data': {\n",
        "        'X_test': X_test,\n",
        "        'y_test': y_test,\n",
        "        'lstm_orig': lstm_orig,\n",
        "        'lstm_recon': lstm_recon,\n",
        "        'timestamps': timestamps\n",
        "    },\n",
        "    'interpreter': interpreter\n",
        "}\n",
        "\n",
        "# Visualize results\n",
        "visualize_results(results_dict)\n",
        "plot_roc_curves(results_dict)\n",
        "plot_precision_recall_curves(results_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Save Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Save models\n",
        "config = {\n",
        "    \"sequence_length\": sequence_length,\n",
        "    \"embedding_dim\": 64\n",
        "}\n",
        "\n",
        "save_trained_models(\n",
        "    models_dict={\n",
        "        \"lstm\": lstm_model,\n",
        "        \"gru\": gru_model,\n",
        "        \"transformer\": transformer_model\n",
        "    },\n",
        "    results_dict={\n",
        "        \"lstm\": lstm_results,\n",
        "        \"gru\": gru_results,\n",
        "        \"transformer\": transformer_results,\n",
        "        \"ensemble\": ensemble_results\n",
        "    },\n",
        "    config=config,\n",
        "    base_path=\"models/autoencoder/\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
