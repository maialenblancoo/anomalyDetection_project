{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0. Directory setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Get current notebook directory\n",
        "notebook_dir = os.getcwd()\n",
        "\n",
        "# Navigate to project root if notebook is in 'notebooks' folder\n",
        "project_dir = notebook_dir\n",
        "if os.path.basename(notebook_dir) == 'notebooks':\n",
        "    project_dir = os.path.dirname(notebook_dir)\n",
        "    os.chdir(project_dir)\n",
        "\n",
        "# Add project root to sys.path if not already included\n",
        "if project_dir not in sys.path:\n",
        "    sys.path.insert(0, project_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Introduction and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import logging\n",
        "\n",
        "# Import custom modules\n",
        "import sys\n",
        "sys.path.append('./')\n",
        "from utils.data_loader import load_data, load_anomaly_labels, normalize_data, create_sequences\n",
        "from utils.data_loader import create_labels_array, split_data, prepare_data_loaders\n",
        "from utils.model_utils import load_trained_models, get_reconstruction_errors, EnsembleModel\n",
        "from utils.evaluation import evaluate_threshold, AnomalyInterpreter, visualize_results\n",
        "from utils.evaluation import plot_roc_curves, plot_precision_recall_curves, create_results_summary, print_results_table\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_context(\"notebook\", font_scale=1.2)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load data\n",
        "filepath = 'data/machine_temperature_system_failure.csv'\n",
        "labels_path = 'data/known_labels_v1.0.json'\n",
        "windows_path = 'data/combined_windows.json'\n",
        "\n",
        "df = load_data(filepath)\n",
        "labels_dict, windows_dict = load_anomaly_labels(labels_path, windows_path)\n",
        "\n",
        "filename = 'realKnownCause/machine_temperature_system_failure.csv'\n",
        "anomaly_timestamps = labels_dict[filename]\n",
        "anomaly_windows = windows_dict[filename]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data_scaled, scaler = normalize_data(df[['value']])\n",
        "\n",
        "sequence_length = 150\n",
        "step = 10\n",
        "\n",
        "X = create_sequences(data_scaled, sequence_length, step)\n",
        "y = create_labels_array(df, anomaly_timestamps, anomaly_windows, sequence_length, step)\n",
        "\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = prepare_data_loaders(X_train, X_val, X_test, batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Model Loading and Reconstruction Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load pretrained models\n",
        "def load_models_with_correct_dimensions():\n",
        "    import json\n",
        "    import os\n",
        "    import torch\n",
        "    from utils.model_utils import LSTMAutoencoder, GRUAutoencoder, TransformerEncoder\n",
        "    \n",
        "    base_path = \"models/autoencoder/\"\n",
        "    \n",
        "    try:\n",
        "        with open(os.path.join(base_path, \"model_metadata.json\"), \"r\") as f:\n",
        "            metadata = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(\"Not found.\")\n",
        "        metadata = {\"embedding_dim\": 64}\n",
        "    \n",
        "    seq_len = sequence_length\n",
        "    n_features = 1\n",
        "    embedding_dim = metadata.get(\"embedding_dim\", 64)\n",
        "    \n",
        "    lstm_model = LSTMAutoencoder(seq_len=seq_len, n_features=n_features, embedding_dim=embedding_dim)\n",
        "    gru_model = GRUAutoencoder(seq_len=seq_len, n_features=n_features, embedding_dim=embedding_dim)\n",
        "    transformer_model = TransformerEncoder(seq_len=seq_len, n_features=n_features, d_model=48, nhead=4)\n",
        "    \n",
        "    # load weights\n",
        "    try:\n",
        "        lstm_model.load_state_dict(torch.load(os.path.join(base_path, \"lstm_model.pt\")))\n",
        "        gru_model.load_state_dict(torch.load(os.path.join(base_path, \"gru_model.pt\")))\n",
        "        transformer_model.load_state_dict(torch.load(os.path.join(base_path, \"transformer_model.pt\")))\n",
        "    except Exception as e:\n",
        "        print(\"\")\n",
        "    \n",
        "    return {\n",
        "        \"lstm\": lstm_model,\n",
        "        \"gru\": gru_model,\n",
        "        \"transformer\": transformer_model\n",
        "    }, metadata\n",
        "\n",
        "models, metadata = load_models_with_correct_dimensions()\n",
        "lstm_model = models[\"lstm\"]\n",
        "gru_model = models[\"gru\"]\n",
        "transformer_model = models[\"transformer\"]\n",
        "\n",
        "# Get reconstruction errors\n",
        "lstm_errors, lstm_orig, lstm_recon = get_reconstruction_errors(lstm_model, test_loader, device)\n",
        "gru_errors, gru_orig, gru_recon = get_reconstruction_errors(gru_model, test_loader, device)\n",
        "transformer_errors, transformer_orig, transformer_recon = get_reconstruction_errors(transformer_model, test_loader, device)\n",
        "\n",
        "val_lstm_errors, _, _ = get_reconstruction_errors(lstm_model, val_loader, device)\n",
        "val_gru_errors, _, _ = get_reconstruction_errors(gru_model, val_loader, device)\n",
        "val_transformer_errors, _, _ = get_reconstruction_errors(transformer_model, val_loader, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Dynamic Threshold Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Function to create dynamic threshold\n",
        "class DynamicThresholdGenerator:\n",
        "    def __init__(self, window_size=30):\n",
        "        self.window_size = window_size\n",
        "    \n",
        "    def rolling_threshold(self, errors, val_errors, factor=1.5, min_percentile=50, max_percentile=99):\n",
        "        base_threshold = np.mean(val_errors) + factor * np.std(val_errors)\n",
        "        thresholds = np.zeros_like(errors)\n",
        "        \n",
        "        for i in range(len(errors)):\n",
        "            start_idx = max(0, i - self.window_size)\n",
        "            end_idx = i\n",
        "            window = errors[start_idx:end_idx]\n",
        "            \n",
        "            if len(window) > 0:\n",
        "                local_mean = np.mean(window)\n",
        "                local_std = np.std(window)\n",
        "                window_threshold = local_mean + factor * local_std\n",
        "                \n",
        "                # Ensure threshold is not too low or too high\n",
        "                min_thresh = np.percentile(val_errors, min_percentile)\n",
        "                max_thresh = np.percentile(val_errors, max_percentile)\n",
        "                \n",
        "                window_threshold = max(min_thresh, min(max_thresh, window_threshold))\n",
        "                thresholds[i] = window_threshold\n",
        "            else:\n",
        "                thresholds[i] = base_threshold\n",
        "        \n",
        "        return thresholds\n",
        "    \n",
        "    def seasonal_threshold(self, errors, timestamps, val_errors, factor=1.5, \n",
        "                          seasonal_periods={\"daily\": 24, \"weekly\": 168}):\n",
        "\n",
        "        if not isinstance(timestamps[0], pd.Timestamp):\n",
        "            timestamps = pd.to_datetime(timestamps)\n",
        "        \n",
        "        thresholds = np.zeros_like(errors)\n",
        "        base_threshold = np.mean(val_errors) + factor * np.std(val_errors)\n",
        "        \n",
        "        # Extract time features\n",
        "        hour_of_day = np.array([ts.hour for ts in timestamps])\n",
        "        day_of_week = np.array([ts.dayofweek for ts in timestamps])\n",
        "        \n",
        "        # Calculate hourly patterns\n",
        "        hourly_means = {}\n",
        "        hourly_stds = {}\n",
        "        \n",
        "        for hour in range(24):\n",
        "            mask = hour_of_day == hour\n",
        "            if np.sum(mask) > 0:\n",
        "                hourly_means[hour] = np.mean(errors[mask])\n",
        "                hourly_stds[hour] = np.std(errors[mask])\n",
        "        \n",
        "        # Calculate daily patterns (by day of week)\n",
        "        daily_means = {}\n",
        "        daily_stds = {}\n",
        "        \n",
        "        for day in range(7):\n",
        "            mask = day_of_week == day\n",
        "            if np.sum(mask) > 0:\n",
        "                daily_means[day] = np.mean(errors[mask])\n",
        "                daily_stds[day] = np.std(errors[mask])\n",
        "        \n",
        "        # Generate thresholds with seasonal adjustments\n",
        "        for i, (ts, error) in enumerate(zip(timestamps, errors)):\n",
        "            hour = ts.hour\n",
        "            day = ts.dayofweek\n",
        "            \n",
        "            # Get seasonal factors\n",
        "            hour_factor = 1.0\n",
        "            if hour in hourly_means:\n",
        "                hour_deviation = (hourly_means[hour] - np.mean(list(hourly_means.values()))) / np.mean(list(hourly_means.values()))\n",
        "                hour_factor = 1.0 + hour_deviation\n",
        "            \n",
        "            day_factor = 1.0\n",
        "            if day in daily_means:\n",
        "                day_deviation = (daily_means[day] - np.mean(list(daily_means.values()))) / np.mean(list(daily_means.values()))\n",
        "                day_factor = 1.0 + day_deviation\n",
        "            \n",
        "            # Combine factors and apply to base threshold\n",
        "            combined_factor = (hour_factor + day_factor) / 2\n",
        "            thresholds[i] = base_threshold * combined_factor\n",
        "        \n",
        "        return thresholds\n",
        "    \n",
        "    def adaptive_threshold(self, errors, val_errors, factor=1.5, adaptivity=0.2):\n",
        "        \n",
        "        base_threshold = np.mean(val_errors) + factor * np.std(val_errors)\n",
        "        thresholds = np.zeros_like(errors)\n",
        "        \n",
        "        # Initial threshold\n",
        "        thresholds[0] = base_threshold\n",
        "        \n",
        "        # Adaptive thresholding\n",
        "        for i in range(1, len(errors)):\n",
        "            current_err_magnitude = errors[i-1] / np.mean(val_errors)\n",
        "            adaptation = 1.0 + adaptivity * (current_err_magnitude - 1.0)\n",
        "            adaptation = max(0.5, min(adaptation, 2.0))  # Limit adaptation factor\n",
        "            \n",
        "            thresholds[i] = base_threshold * adaptation\n",
        "        \n",
        "        return thresholds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Threshold Application and Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create dynamic thresholds\n",
        "threshold_generator = DynamicThresholdGenerator(window_size=40)\n",
        "\n",
        "# Evaluate with each threshold type\n",
        "# 1. Rolling threshold\n",
        "rolling_lstm_thresholds = threshold_generator.rolling_threshold(lstm_errors, val_lstm_errors, factor=1.5)\n",
        "rolling_gru_thresholds = threshold_generator.rolling_threshold(gru_errors, val_gru_errors, factor=1.5)\n",
        "rolling_transformer_thresholds = threshold_generator.rolling_threshold(transformer_errors, val_transformer_errors, factor=1.5)\n",
        "\n",
        "# 2. Seasonal threshold (assuming we have timestamps)\n",
        "timestamps = df.index[sequence_length:][::step][-len(lstm_errors):]\n",
        "seasonal_lstm_thresholds = threshold_generator.seasonal_threshold(lstm_errors, timestamps, val_lstm_errors)\n",
        "seasonal_gru_thresholds = threshold_generator.seasonal_threshold(gru_errors, timestamps, val_gru_errors)\n",
        "seasonal_transformer_thresholds = threshold_generator.seasonal_threshold(transformer_errors, timestamps, val_transformer_errors)\n",
        "\n",
        "# 3. Adaptive threshold\n",
        "adaptive_lstm_thresholds = threshold_generator.adaptive_threshold(lstm_errors, val_lstm_errors)\n",
        "adaptive_gru_thresholds = threshold_generator.adaptive_threshold(gru_errors, val_gru_errors)\n",
        "adaptive_transformer_thresholds = threshold_generator.adaptive_threshold(transformer_errors, val_transformer_errors)\n",
        "\n",
        "# Create ensemble model\n",
        "ensemble = EnsembleModel(\n",
        "    models=[lstm_model, gru_model, transformer_model],\n",
        "    names=[\"LSTM\", \"GRU\", \"Transformer\"]\n",
        ")\n",
        "\n",
        "ensemble.optimize_weights(\n",
        "    [val_lstm_errors, val_gru_errors, val_transformer_errors],\n",
        "    y_val\n",
        ")\n",
        "\n",
        "ensemble_errors, individual_errors = ensemble.get_weighted_errors(\n",
        "    [test_loader, test_loader, test_loader],\n",
        "    device\n",
        ")\n",
        "\n",
        "val_ensemble_errors, _ = ensemble.get_weighted_errors(\n",
        "    [val_loader, val_loader, val_loader],\n",
        "    device\n",
        ")\n",
        "\n",
        "# Create dynamic thresholds for ensemble\n",
        "rolling_ensemble_thresholds = threshold_generator.rolling_threshold(ensemble_errors, val_ensemble_errors)\n",
        "seasonal_ensemble_thresholds = threshold_generator.seasonal_threshold(ensemble_errors, timestamps, val_ensemble_errors)\n",
        "adaptive_ensemble_thresholds = threshold_generator.adaptive_threshold(ensemble_errors, val_ensemble_errors)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Evaluation and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Evaluate dynamic thresholds\n",
        "\n",
        "def evaluate_with_dynamic_threshold(errors, y_true, thresholds):\n",
        "    y_pred = (errors > thresholds).astype(int)\n",
        "    \n",
        "    from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "    \n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average='binary', zero_division=0\n",
        "    )\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "    try:\n",
        "        auc_roc = roc_auc_score(y_true, errors)\n",
        "    except:\n",
        "        auc_roc = np.nan\n",
        "\n",
        "    precision_pr, recall_pr, _ = precision_recall_curve(y_true, errors)\n",
        "    auc_pr = auc(recall_pr, precision_pr)\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'tn': tn,\n",
        "        'fp': fp,\n",
        "        'fn': fn,\n",
        "        'tp': tp,\n",
        "        'auc_roc': auc_roc,\n",
        "        'auc_pr': auc_pr,\n",
        "        'threshold_mean': np.mean(thresholds),\n",
        "        'threshold_std': np.std(thresholds)\n",
        "    }\n",
        "\n",
        "# Evaluate all models with all threshold types\n",
        "# Static threshold (baseline)\n",
        "static_lstm_results = evaluate_threshold(lstm_errors, y_test, val_lstm_errors, factor=1.5)\n",
        "static_gru_results = evaluate_threshold(gru_errors, y_test, val_gru_errors, factor=1.5)\n",
        "static_transformer_results = evaluate_threshold(transformer_errors, y_test, val_transformer_errors, factor=1.5)\n",
        "static_ensemble_results = evaluate_threshold(ensemble_errors, y_test, val_ensemble_errors, factor=1.5)\n",
        "\n",
        "# Rolling threshold\n",
        "rolling_lstm_results = evaluate_with_dynamic_threshold(lstm_errors, y_test, rolling_lstm_thresholds)\n",
        "rolling_gru_results = evaluate_with_dynamic_threshold(gru_errors, y_test, rolling_gru_thresholds)\n",
        "rolling_transformer_results = evaluate_with_dynamic_threshold(transformer_errors, y_test, rolling_transformer_thresholds)\n",
        "rolling_ensemble_results = evaluate_with_dynamic_threshold(ensemble_errors, y_test, rolling_ensemble_thresholds)\n",
        "\n",
        "# Seasonal threshold\n",
        "seasonal_lstm_results = evaluate_with_dynamic_threshold(lstm_errors, y_test, seasonal_lstm_thresholds)\n",
        "seasonal_gru_results = evaluate_with_dynamic_threshold(gru_errors, y_test, seasonal_gru_thresholds)\n",
        "seasonal_transformer_results = evaluate_with_dynamic_threshold(transformer_errors, y_test, seasonal_transformer_thresholds)\n",
        "seasonal_ensemble_results = evaluate_with_dynamic_threshold(ensemble_errors, y_test, seasonal_ensemble_thresholds)\n",
        "\n",
        "# Adaptive threshold\n",
        "adaptive_lstm_results = evaluate_with_dynamic_threshold(lstm_errors, y_test, adaptive_lstm_thresholds)\n",
        "adaptive_gru_results = evaluate_with_dynamic_threshold(gru_errors, y_test, adaptive_gru_thresholds)\n",
        "adaptive_transformer_results = evaluate_with_dynamic_threshold(transformer_errors, y_test, adaptive_transformer_thresholds)\n",
        "adaptive_ensemble_results = evaluate_with_dynamic_threshold(ensemble_errors, y_test, adaptive_ensemble_thresholds)\n",
        "\n",
        "# Compare threshold approaches\n",
        "print(\"\\n=== Comparison of Threshold Approaches (Ensemble Model) ===\")\n",
        "print(f\"{'Approach':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'FP':<6} {'FN':<6}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "print(f\"{'Static':<15} {static_ensemble_results['precision']:<10.4f} {static_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{static_ensemble_results['f1']:<10.4f} {static_ensemble_results['fp']:<6d} {static_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Rolling':<15} {rolling_ensemble_results['precision']:<10.4f} {rolling_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{rolling_ensemble_results['f1']:<10.4f} {rolling_ensemble_results['fp']:<6d} {rolling_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Seasonal':<15} {seasonal_ensemble_results['precision']:<10.4f} {seasonal_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{seasonal_ensemble_results['f1']:<10.4f} {seasonal_ensemble_results['fp']:<6d} {seasonal_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Adaptive':<15} {adaptive_ensemble_results['precision']:<10.4f} {adaptive_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{adaptive_ensemble_results['f1']:<10.4f} {adaptive_ensemble_results['fp']:<6d} {adaptive_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "# Visualize threshold comparison\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(ensemble_errors, label='Error', alpha=0.7)\n",
        "plt.axhline(y=static_ensemble_results['threshold'], color='r', linestyle='-', label='Static')\n",
        "plt.fill_between(range(len(y_test)), 0, 1, where=y_test > 0, alpha=0.3, color='red', transform=plt.gca().get_xaxis_transform())\n",
        "plt.ylim(0, max(ensemble_errors) * 1.1)\n",
        "plt.legend()\n",
        "plt.title('Static Threshold')\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(ensemble_errors, label='Error', alpha=0.7)\n",
        "plt.plot(rolling_ensemble_thresholds, label='Rolling', color='g', linestyle='-')\n",
        "plt.fill_between(range(len(y_test)), 0, 1, where=y_test > 0, alpha=0.3, color='red', transform=plt.gca().get_xaxis_transform())\n",
        "plt.ylim(0, max(ensemble_errors) * 1.1)\n",
        "plt.legend()\n",
        "plt.title('Rolling Threshold')\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "plt.plot(ensemble_errors, label='Error', alpha=0.7)\n",
        "plt.plot(seasonal_ensemble_thresholds, label='Seasonal', color='purple', linestyle='-')\n",
        "plt.fill_between(range(len(y_test)), 0, 1, where=y_test > 0, alpha=0.3, color='red', transform=plt.gca().get_xaxis_transform())\n",
        "plt.ylim(0, max(ensemble_errors) * 1.1)\n",
        "plt.legend()\n",
        "plt.title('Seasonal Threshold')\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "plt.plot(ensemble_errors, label='Error', alpha=0.7)\n",
        "plt.plot(adaptive_ensemble_thresholds, label='Adaptive', color='orange', linestyle='-')\n",
        "plt.fill_between(range(len(y_test)), 0, 1, where=y_test > 0, alpha=0.3, color='red', transform=plt.gca().get_xaxis_transform())\n",
        "plt.ylim(0, max(ensemble_errors) * 1.1)\n",
        "plt.legend()\n",
        "plt.title('Adaptive Threshold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('threshold_comparison.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Hybrid Threshold Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Implement hybrid threshold approach\n",
        "class HybridThresholdGenerator:\n",
        "    def __init__(self, window_size=30):\n",
        "        self.window_size = window_size\n",
        "        self.threshold_generator = DynamicThresholdGenerator(window_size)\n",
        "    \n",
        "    def hybrid_threshold(self, errors, timestamps, val_errors, weights=(0.4, 0.3, 0.3), factor=1.5):\n",
        "       \n",
        "        rolling_thresholds = self.threshold_generator.rolling_threshold(errors, val_errors, factor)\n",
        "        seasonal_thresholds = self.threshold_generator.seasonal_threshold(errors, timestamps, val_errors, factor)\n",
        "        adaptive_thresholds = self.threshold_generator.adaptive_threshold(errors, val_errors, factor)\n",
        "        \n",
        "        hybrid_thresholds = (\n",
        "            weights[0] * rolling_thresholds + \n",
        "            weights[1] * seasonal_thresholds + \n",
        "            weights[2] * adaptive_thresholds\n",
        "        )\n",
        "        \n",
        "        return hybrid_thresholds\n",
        "\n",
        "# Create hybrid thresholds\n",
        "hybrid_generator = HybridThresholdGenerator(window_size=40)\n",
        "hybrid_ensemble_thresholds = hybrid_generator.hybrid_threshold(\n",
        "    ensemble_errors, timestamps, val_ensemble_errors\n",
        ")\n",
        "\n",
        "# Evaluate hybrid approach\n",
        "hybrid_ensemble_results = evaluate_with_dynamic_threshold(ensemble_errors, y_test, hybrid_ensemble_thresholds)\n",
        "\n",
        "print(\"\\n=== Hybrid Threshold Results (Ensemble Model) ===\")\n",
        "print(f\"Precision: {hybrid_ensemble_results['precision']:.4f}\")\n",
        "print(f\"Recall: {hybrid_ensemble_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {hybrid_ensemble_results['f1']:.4f}\")\n",
        "print(f\"FP: {hybrid_ensemble_results['fp']}, FN: {hybrid_ensemble_results['fn']}\")\n",
        "\n",
        "# Visualize hybrid approach\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(ensemble_errors, label='Error', alpha=0.7)\n",
        "plt.plot(hybrid_ensemble_thresholds, label='Hybrid Threshold', color='green', linestyle='-')\n",
        "plt.plot(static_ensemble_results['threshold'] * np.ones_like(ensemble_errors), \n",
        "         label='Static Threshold', color='red', linestyle='--')\n",
        "plt.fill_between(range(len(y_test)), 0, 1, where=y_test > 0, alpha=0.3, color='red', transform=plt.gca().get_xaxis_transform())\n",
        "plt.ylim(0, max(ensemble_errors) * 1.1)\n",
        "plt.legend()\n",
        "plt.title('Hybrid Threshold Approach vs Static Threshold')\n",
        "plt.savefig('hybrid_threshold.png', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Model Saving and Application Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Create a function to find optimal weights\n",
        "def optimize_hybrid_weights(errors, timestamps, val_errors, y_true, n_trials=20):\n",
        "    from itertools import product\n",
        "    \n",
        "    best_f1 = 0\n",
        "    best_weights = (0.33, 0.33, 0.33)  # Default equal weights\n",
        "    \n",
        "    # Generate weight combinations that sum to 1\n",
        "    weight_options = np.linspace(0, 1, 6)  # [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
        "    valid_weights = []\n",
        "    \n",
        "    for w1, w2 in product(weight_options, weight_options):\n",
        "        w3 = 1.0 - w1 - w2\n",
        "        if 0 <= w3 <= 1:\n",
        "            valid_weights.append((w1, w2, w3))\n",
        "    \n",
        "    hybrid_gen = HybridThresholdGenerator()\n",
        "    \n",
        "    for weights in valid_weights:\n",
        "        hybrid_thresholds = hybrid_gen.hybrid_threshold(\n",
        "            errors, timestamps, val_errors, weights=weights\n",
        "        )\n",
        "        \n",
        "        results = evaluate_with_dynamic_threshold(errors, y_true, hybrid_thresholds)\n",
        "        f1 = results['f1']\n",
        "        \n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_weights = weights\n",
        "    \n",
        "    print(f\"Best weights found: {best_weights} with F1-Score: {best_f1:.4f}\")\n",
        "    return best_weights\n",
        "\n",
        "# Find optimal weights\n",
        "best_weights = optimize_hybrid_weights(ensemble_errors, timestamps, val_ensemble_errors, y_test)\n",
        "\n",
        "# Create optimized hybrid threshold\n",
        "optimized_ensemble_thresholds = hybrid_generator.hybrid_threshold(\n",
        "    ensemble_errors, timestamps, val_ensemble_errors, weights=best_weights\n",
        ")\n",
        "\n",
        "# Evaluate optimized hybrid approach\n",
        "optimized_ensemble_results = evaluate_with_dynamic_threshold(ensemble_errors, y_test, optimized_ensemble_thresholds)\n",
        "\n",
        "print(\"\\n=== Optimized Hybrid Threshold Results (Ensemble Model) ===\")\n",
        "print(f\"Precision: {optimized_ensemble_results['precision']:.4f}\")\n",
        "print(f\"Recall: {optimized_ensemble_results['recall']:.4f}\")\n",
        "print(f\"F1-Score: {optimized_ensemble_results['f1']:.4f}\")\n",
        "print(f\"FP: {optimized_ensemble_results['fp']}, FN: {optimized_ensemble_results['fn']}\")\n",
        "\n",
        "# Compare all approaches\n",
        "print(\"\\n=== Final Comparison of All Threshold Approaches (Ensemble Model) ===\")\n",
        "print(f\"{'Approach':<20} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'FP':<6} {'FN':<6}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(f\"{'Static':<20} {static_ensemble_results['precision']:<10.4f} {static_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{static_ensemble_results['f1']:<10.4f} {static_ensemble_results['fp']:<6d} {static_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Rolling':<20} {rolling_ensemble_results['precision']:<10.4f} {rolling_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{rolling_ensemble_results['f1']:<10.4f} {rolling_ensemble_results['fp']:<6d} {rolling_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Seasonal':<20} {seasonal_ensemble_results['precision']:<10.4f} {seasonal_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{seasonal_ensemble_results['f1']:<10.4f} {seasonal_ensemble_results['fp']:<6d} {seasonal_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Adaptive':<20} {adaptive_ensemble_results['precision']:<10.4f} {adaptive_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{adaptive_ensemble_results['f1']:<10.4f} {adaptive_ensemble_results['fp']:<6d} {adaptive_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Hybrid (Equal)':<20} {hybrid_ensemble_results['precision']:<10.4f} {hybrid_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{hybrid_ensemble_results['f1']:<10.4f} {hybrid_ensemble_results['fp']:<6d} {hybrid_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "print(f\"{'Hybrid (Optimized)':<20} {optimized_ensemble_results['precision']:<10.4f} {optimized_ensemble_results['recall']:<10.4f} \"\n",
        "      f\"{optimized_ensemble_results['f1']:<10.4f} {optimized_ensemble_results['fp']:<6d} {optimized_ensemble_results['fn']:<6d}\")\n",
        "\n",
        "# Save best threshold model\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "os.makedirs(\"models/dynamic_thresholds/\", exist_ok=True)\n",
        "\n",
        "# Save the threshold generator and best weights\n",
        "threshold_model = {\n",
        "    'generator': hybrid_generator,\n",
        "    'best_weights': best_weights,\n",
        "    'validation_errors': {\n",
        "        'lstm': val_lstm_errors,\n",
        "        'gru': val_gru_errors,\n",
        "        'transformer': val_transformer_errors,\n",
        "        'ensemble': val_ensemble_errors\n",
        "    },\n",
        "    'factor': 1.5\n",
        "}\n",
        "\n",
        "with open(\"models/dynamic_thresholds/hybrid_threshold_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(threshold_model, f)\n",
        "\n",
        "print(\"Hybrid threshold model saved to models/dynamic_thresholds/hybrid_threshold_model.pkl\")\n",
        "\n",
        "# Function to load threshold model\n",
        "def load_dynamic_threshold(path=\"models/dynamic_thresholds/hybrid_threshold_model.pkl\"):\n",
        "    with open(path, \"rb\") as f:\n",
        "        threshold_model = pickle.load(f)\n",
        "    \n",
        "    def apply_dynamic_threshold(errors, timestamps):\n",
        "        generator = threshold_model['generator']\n",
        "        weights = threshold_model['best_weights']\n",
        "        val_errors = threshold_model['validation_errors']['ensemble']\n",
        "        factor = threshold_model['factor']\n",
        "        \n",
        "        return generator.hybrid_threshold(errors, timestamps, val_errors, weights, factor)\n",
        "    \n",
        "    return apply_dynamic_threshold\n",
        "\n",
        "# Create function to apply dynamic thresholds\n",
        "def apply_dynamic_thresholds(new_data, models, threshold_fn, device='cpu'):\n",
        "    # Prepare data\n",
        "    new_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(torch.FloatTensor(new_data)),\n",
        "        batch_size=64,\n",
        "        shuffle=False\n",
        "    )\n",
        "    \n",
        "    # Get ensemble errors\n",
        "    ensemble = EnsembleModel(\n",
        "        models=[models['lstm'], models['gru'], models['transformer']],\n",
        "        names=[\"LSTM\", \"GRU\", \"Transformer\"],\n",
        "        weights=[0.4, 0.3, 0.3]  # Example weights, should be optimized\n",
        "    )\n",
        "    \n",
        "    ensemble_errors, _ = ensemble.get_weighted_errors(\n",
        "        [new_loader, new_loader, new_loader],\n",
        "        device\n",
        "    )\n",
        "    \n",
        "    # Get timestamps (assuming we have them)\n",
        "    timestamps = pd.date_range(start='2022-01-01', periods=len(ensemble_errors), freq='H')\n",
        "    \n",
        "    # Apply dynamic threshold\n",
        "    thresholds = threshold_fn(ensemble_errors, timestamps)\n",
        "    \n",
        "    # Detect anomalies\n",
        "    anomalies = ensemble_errors > thresholds\n",
        "    \n",
        "    return {\n",
        "        'errors': ensemble_errors,\n",
        "        'thresholds': thresholds,\n",
        "        'anomalies': anomalies,\n",
        "        'anomaly_scores': ensemble_errors / thresholds\n",
        "    }\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
