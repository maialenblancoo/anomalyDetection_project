{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6814774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio actual: c:\\Users\\aleja\\Desktop\\deepProject\\anomalyDetection_project\\notebooks\n",
      "Cambiado a directorio: c:\\Users\\aleja\\Desktop\\deepProject\\anomalyDetection_project\n",
      "Añadido al path: c:\\Users\\aleja\\Desktop\\deepProject\\anomalyDetection_project\n",
      "Contenido del directorio raíz: ['.git', 'data', 'ensemble_prediction_sample.png', 'error_distribution.png', 'gru_prediction_sample.png', 'hybrid_threshold.png', 'lstm_prediction_sample.png', 'lstm_transfer_comparison.png', 'models', 'model_comparison.png', 'notebooks', 'results', 'threshold_comparison.png', 'transfer_learning_anomalies.png', 'transformer_prediction_sample.png', 'utils']\n",
      "Contenido de utils: ['data_loader.py', 'evaluation.py', 'model_utils.py', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Obtener el directorio actual del notebook\n",
    "notebook_dir = os.getcwd()\n",
    "print(\"Directorio actual:\", notebook_dir)\n",
    "\n",
    "# Ir al directorio raíz del proyecto (si el notebook está en la carpeta notebooks)\n",
    "project_dir = notebook_dir\n",
    "if os.path.basename(notebook_dir) == 'notebooks':\n",
    "    project_dir = os.path.dirname(notebook_dir)\n",
    "    os.chdir(project_dir)\n",
    "    print(\"Cambiado a directorio:\", os.getcwd())\n",
    "else:\n",
    "    print(\"Ya parece estar en el directorio raíz\")\n",
    "\n",
    "# Añadir el directorio raíz al path\n",
    "if project_dir not in sys.path:\n",
    "    sys.path.insert(0, project_dir)\n",
    "    print(\"Añadido al path:\", project_dir)\n",
    "else:\n",
    "    print(\"El directorio ya está en el path\")\n",
    "\n",
    "# Verificar que utils esté accesible\n",
    "print(\"Contenido del directorio raíz:\", os.listdir())\n",
    "print(\"Contenido de utils:\", os.listdir('utils') if os.path.exists('utils') else \"La carpeta utils no existe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78eb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 20:14:53,345 - INFO - Usando dispositivo: cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TransformerEncoder:\n\tsize mismatch for pos_embedding: copying a param with shape torch.Size([1, 150, 48]) from checkpoint, the shape in current model is torch.Size([1, 150, 64]).\n\tsize mismatch for input_projection.weight: copying a param with shape torch.Size([48, 1]) from checkpoint, the shape in current model is torch.Size([64, 1]).\n\tsize mismatch for input_projection.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([48, 48]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 48]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([48, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([48, 48]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([128, 48]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([48, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_projection.weight: copying a param with shape torch.Size([1, 48]) from checkpoint, the shape in current model is torch.Size([1, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 339\u001b[39m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIntegrated analysis completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 321\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# Load all models\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     models = \u001b[43mload_all_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;66;03m# Load a test dataset\u001b[39;00m\n\u001b[32m    324\u001b[39m     filepath = \u001b[33m'\u001b[39m\u001b[33mdata/machine_temperature_system_failure.csv\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mload_all_models\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load all trained models from various components.\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Load autoencoder models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m autoencoder_models, autoencoder_metadata = \u001b[43mload_trained_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/autoencoder/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Load dynamic threshold function\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aleja\\Desktop\\deepProject\\anomalyDetection_project\\utils\\model_utils.py:158\u001b[39m, in \u001b[36mload_trained_models\u001b[39m\u001b[34m(seq_len, n_features, base_path)\u001b[39m\n\u001b[32m    156\u001b[39m lstm_model.load_state_dict(torch.load(os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mlstm_model.pt\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m    157\u001b[39m gru_model.load_state_dict(torch.load(os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mgru_model.pt\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43mtransformer_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtransformer_model.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModelos cargados desde \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    163\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlstm\u001b[39m\u001b[33m\"\u001b[39m: lstm_model,\n\u001b[32m    164\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgru\u001b[39m\u001b[33m\"\u001b[39m: gru_model,\n\u001b[32m    165\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtransformer\u001b[39m\u001b[33m\"\u001b[39m: transformer_model\n\u001b[32m    166\u001b[39m }, metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:2581\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2573\u001b[39m         error_msgs.insert(\n\u001b[32m   2574\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2575\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2576\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2577\u001b[39m             ),\n\u001b[32m   2578\u001b[39m         )\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2583\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2584\u001b[39m         )\n\u001b[32m   2585\u001b[39m     )\n\u001b[32m   2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for TransformerEncoder:\n\tsize mismatch for pos_embedding: copying a param with shape torch.Size([1, 150, 48]) from checkpoint, the shape in current model is torch.Size([1, 150, 64]).\n\tsize mismatch for input_projection.weight: copying a param with shape torch.Size([48, 1]) from checkpoint, the shape in current model is torch.Size([64, 1]).\n\tsize mismatch for input_projection.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_weight: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.in_proj_bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.weight: copying a param with shape torch.Size([48, 48]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer_encoder.layers.0.self_attn.out_proj.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.linear1.weight: copying a param with shape torch.Size([128, 48]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for transformer_encoder.layers.0.linear2.weight: copying a param with shape torch.Size([48, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for transformer_encoder.layers.0.linear2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.0.norm2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_weight: copying a param with shape torch.Size([144, 48]) from checkpoint, the shape in current model is torch.Size([192, 64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.in_proj_bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([192]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.weight: copying a param with shape torch.Size([48, 48]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for transformer_encoder.layers.1.self_attn.out_proj.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.linear1.weight: copying a param with shape torch.Size([128, 48]) from checkpoint, the shape in current model is torch.Size([128, 64]).\n\tsize mismatch for transformer_encoder.layers.1.linear2.weight: copying a param with shape torch.Size([48, 128]) from checkpoint, the shape in current model is torch.Size([64, 128]).\n\tsize mismatch for transformer_encoder.layers.1.linear2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm1.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm1.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for transformer_encoder.layers.1.norm2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for output_projection.weight: copying a param with shape torch.Size([1, 48]) from checkpoint, the shape in current model is torch.Size([1, 64])."
     ]
    }
   ],
   "source": [
    "# **Integrated Anomaly Detection System**\n",
    "# \n",
    "# This notebook integrates all components for a complete anomaly detection system.\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils.data_loader import load_data, normalize_data, create_sequences\n",
    "from utils.model_utils import get_reconstruction_errors, EnsembleModel, load_trained_models\n",
    "from utils.evaluation import AnomalyInterpreter\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Load all models\n",
    "# Load all models\n",
    "def load_all_models():\n",
    "    \"\"\"Load all trained models from various components.\"\"\"\n",
    "    \n",
    "    # Custom function to load autoencoder models with correct dimensions\n",
    "    def load_autoencoder_models(base_path=\"models/autoencoder/\"):\n",
    "        \"\"\"Carga modelos con las dimensiones correctas.\"\"\"\n",
    "        import json\n",
    "        import os\n",
    "        import torch\n",
    "        from utils.model_utils import LSTMAutoencoder, GRUAutoencoder, TransformerEncoder\n",
    "        \n",
    "        try:\n",
    "            with open(os.path.join(base_path, \"model_metadata.json\"), \"r\") as f:\n",
    "                metadata = json.load(f)\n",
    "                logger.info(f\"Metadatos cargados: {metadata}\")\n",
    "        except FileNotFoundError:\n",
    "            logger.warning(\"Archivo de metadatos no encontrado, usando valores por defecto.\")\n",
    "            metadata = {\"sequence_length\": 150, \"embedding_dim\": 64}\n",
    "        \n",
    "        seq_len = metadata.get(\"sequence_length\", 150)\n",
    "        n_features = 1\n",
    "        embedding_dim = metadata.get(\"embedding_dim\", 64)\n",
    "        \n",
    "        # Importante: usar d_model=48 para el Transformer\n",
    "        lstm_model = LSTMAutoencoder(seq_len=seq_len, n_features=n_features, embedding_dim=embedding_dim)\n",
    "        gru_model = GRUAutoencoder(seq_len=seq_len, n_features=n_features, embedding_dim=embedding_dim)\n",
    "        transformer_model = TransformerEncoder(seq_len=seq_len, n_features=n_features, d_model=48, nhead=4)\n",
    "        \n",
    "        # Cargar pesos\n",
    "        try:\n",
    "            lstm_model.load_state_dict(torch.load(os.path.join(base_path, \"lstm_model.pt\")))\n",
    "            gru_model.load_state_dict(torch.load(os.path.join(base_path, \"gru_model.pt\")))\n",
    "            transformer_model.load_state_dict(torch.load(os.path.join(base_path, \"transformer_model.pt\")))\n",
    "            logger.info(f\"Modelos cargados correctamente desde {base_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error al cargar modelos: {e}\")\n",
    "        \n",
    "        return {\n",
    "            \"lstm\": lstm_model,\n",
    "            \"gru\": gru_model,\n",
    "            \"transformer\": transformer_model\n",
    "        }, metadata\n",
    "    \n",
    "    # Cargar modelos de autoencoder con la función personalizada\n",
    "    autoencoder_models, autoencoder_metadata = load_autoencoder_models()\n",
    "    \n",
    "    # Load dynamic threshold function\n",
    "    try:\n",
    "        with open(\"models/dynamic_thresholds/hybrid_threshold_model.pkl\", \"rb\") as f:\n",
    "            threshold_model = pickle.load(f)\n",
    "        \n",
    "        def apply_dynamic_threshold(errors, timestamps):\n",
    "            generator = threshold_model['generator']\n",
    "            weights = threshold_model['best_weights']\n",
    "            val_errors = threshold_model['validation_errors']['ensemble']\n",
    "            factor = threshold_model['factor']\n",
    "            return generator.hybrid_threshold(errors, timestamps, val_errors, weights, factor)\n",
    "        \n",
    "        dynamic_threshold_fn = apply_dynamic_threshold\n",
    "    except:\n",
    "        logger.warning(\"Dynamic threshold model not found. Using static threshold.\")\n",
    "        dynamic_threshold_fn = None\n",
    "    \n",
    "    # Load prediction models\n",
    "    try:\n",
    "        from utils.model_utils import load_prediction_models\n",
    "        prediction_models = load_prediction_models(base_path=\"models/prediction/\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Prediction models not found: {e}\")\n",
    "        prediction_models = None\n",
    "    \n",
    "    # Load transfer learning models\n",
    "    try:\n",
    "        # Custom function to load transfer models\n",
    "        def load_transfer_models(base_path=\"models/transfer/\"):\n",
    "            \"\"\"Load transfer learned models.\"\"\"\n",
    "            try:\n",
    "                # Load metadata\n",
    "                with open(os.path.join(base_path, \"transfer_metadata.json\"), \"r\") as f:\n",
    "                    metadata = json.load(f)\n",
    "                \n",
    "                # Load thresholds\n",
    "                with open(os.path.join(base_path, \"thresholds.json\"), \"r\") as f:\n",
    "                    thresholds = json.load(f)\n",
    "                \n",
    "                # Load ensemble weights\n",
    "                with open(os.path.join(base_path, \"ensemble_weights.json\"), \"r\") as f:\n",
    "                    weights_dict = json.load(f)\n",
    "                \n",
    "                return {\n",
    "                    \"metadata\": metadata,\n",
    "                    \"thresholds\": thresholds,\n",
    "                    \"weights\": weights_dict\n",
    "                }\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error loading transfer model files: {e}\")\n",
    "                return None\n",
    "        \n",
    "        transfer_models = load_transfer_models(base_path=\"models/transfer/\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Transfer learning models not found: {e}\")\n",
    "        transfer_models = None\n",
    "    \n",
    "    return {\n",
    "        \"autoencoder\": {\n",
    "            \"models\": autoencoder_models,\n",
    "            \"metadata\": autoencoder_metadata\n",
    "        },\n",
    "        \"dynamic_threshold\": dynamic_threshold_fn,\n",
    "        \"prediction\": prediction_models,\n",
    "        \"transfer\": transfer_models\n",
    "    }\n",
    "\n",
    "# Integrated analysis function\n",
    "def analyze_time_series(new_data, models, scaler=None, device='cpu'):\n",
    "    \"\"\"Analyze a time series using all available models.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Preprocess data\n",
    "    if scaler is None:\n",
    "        data_scaled, scaler = normalize_data(new_data)\n",
    "    else:\n",
    "        data_scaled = scaler.transform(new_data.values.reshape(-1, 1))\n",
    "    \n",
    "    # Get sequence length from metadata\n",
    "    sequence_length = models['autoencoder']['metadata']['sequence_length']\n",
    "    \n",
    "    # Create sequences\n",
    "    X = create_sequences(data_scaled, seq_length=sequence_length, step=1)\n",
    "    \n",
    "    # Convert to tensor and create loader\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(X_tensor),\n",
    "        batch_size=64,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # 1. Detect anomalies using autoencoders\n",
    "    autoencoder_models = models['autoencoder']['models']\n",
    "    \n",
    "    lstm_errors, lstm_orig, lstm_recon = get_reconstruction_errors(\n",
    "        autoencoder_models['lstm'], data_loader, device\n",
    "    )\n",
    "    \n",
    "    gru_errors, gru_orig, gru_recon = get_reconstruction_errors(\n",
    "        autoencoder_models['gru'], data_loader, device\n",
    "    )\n",
    "    \n",
    "    transformer_errors, transformer_orig, transformer_recon = get_reconstruction_errors(\n",
    "        autoencoder_models['transformer'], data_loader, device\n",
    "    )\n",
    "    \n",
    "    # Create ensemble\n",
    "    ensemble = EnsembleModel(\n",
    "        models=[autoencoder_models['lstm'], autoencoder_models['gru'], autoencoder_models['transformer']],\n",
    "        names=[\"LSTM\", \"GRU\", \"Transformer\"]\n",
    "    )\n",
    "    \n",
    "    ensemble_errors, _ = ensemble.get_weighted_errors(\n",
    "        [data_loader] * 3,\n",
    "        device\n",
    "    )\n",
    "    # 2. Apply dynamic thresholds if available\n",
    "    timestamps = pd.date_range(start='2022-01-01', periods=len(ensemble_errors), freq='H')\n",
    "    \n",
    "    if models['dynamic_threshold'] is not None:\n",
    "        dynamic_threshold_fn = models['dynamic_threshold']\n",
    "        thresholds = dynamic_threshold_fn(ensemble_errors, timestamps)\n",
    "    else:\n",
    "        # Use static threshold\n",
    "        val_errors = np.random.choice(ensemble_errors, size=int(len(ensemble_errors)*0.3))\n",
    "        thresholds = np.mean(val_errors) + 1.5 * np.std(val_errors)\n",
    "    \n",
    "    # Detect anomalies\n",
    "    anomalies = ensemble_errors > thresholds\n",
    "    \n",
    "    # Store anomaly detection results\n",
    "    results[\"anomalies\"] = {\n",
    "        \"errors\": {\n",
    "            \"lstm\": lstm_errors,\n",
    "            \"gru\": gru_errors,\n",
    "            \"transformer\": transformer_errors,\n",
    "            \"ensemble\": ensemble_errors\n",
    "        },\n",
    "        \"reconstructions\": {\n",
    "            \"lstm\": (lstm_orig, lstm_recon),\n",
    "            \"gru\": (gru_orig, gru_recon),\n",
    "            \"transformer\": (transformer_orig, transformer_recon)\n",
    "        },\n",
    "        \"thresholds\": thresholds,\n",
    "        \"anomaly_indices\": np.where(anomalies)[0],\n",
    "        \"anomaly_scores\": ensemble_errors / (thresholds if isinstance(thresholds, np.ndarray) else np.array([thresholds] * len(ensemble_errors)))\n",
    "    }\n",
    "    \n",
    "    # 3. Make predictions if models available\n",
    "    if models['prediction'] is not None:\n",
    "        prediction_models = models['prediction']\n",
    "        \n",
    "        # Use most recent data for prediction\n",
    "        if len(data_scaled) >= sequence_length:\n",
    "            recent_data = data_scaled[-sequence_length:].reshape(1, sequence_length, 1)\n",
    "        else:\n",
    "            # If not enough data, pad with zeros\n",
    "            pad_size = sequence_length - len(data_scaled)\n",
    "            padding = np.zeros((pad_size, 1))\n",
    "            recent_data = np.concatenate([padding, data_scaled]).reshape(1, sequence_length, 1)\n",
    "        \n",
    "        # Make predictions with ensemble model\n",
    "        ensemble_predictor = prediction_models['ensemble']\n",
    "        predictions = ensemble_predictor.predict(recent_data, device)\n",
    "        \n",
    "        # Inverse transform predictions\n",
    "        if scaler is not None:\n",
    "            predictions = scaler.inverse_transform(predictions.squeeze()).reshape(-1, 1)\n",
    "        \n",
    "        results[\"predictions\"] = {\n",
    "            \"values\": predictions,\n",
    "            \"horizon\": prediction_models['config']['prediction_horizon']\n",
    "        }\n",
    "    \n",
    "    # 4. Analyze anomalies\n",
    "    interpreter = AnomalyInterpreter(\n",
    "        model=None,\n",
    "        test_data=lstm_orig,\n",
    "        reconstructed_data=lstm_recon,\n",
    "        errors=ensemble_errors,\n",
    "        thresholds=thresholds,\n",
    "        timestamps=timestamps\n",
    "    )\n",
    "    \n",
    "    top_anomalies = interpreter.analyze_top_anomalies(top_k=5)\n",
    "    results[\"analysis\"] = {\n",
    "        \"top_anomalies\": top_anomalies,\n",
    "        \"interpreter\": interpreter\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to visualize integrated results\n",
    "def visualize_integrated_results(new_data, results):\n",
    "    \"\"\"Visualize the integrated analysis results.\"\"\"\n",
    "    \n",
    "    # 1. Anomaly detection visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    errors = results[\"anomalies\"][\"errors\"][\"ensemble\"]\n",
    "    thresholds = results[\"anomalies\"][\"thresholds\"]\n",
    "    anomaly_indices = results[\"anomalies\"][\"anomaly_indices\"]\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(new_data, label='Original Data')\n",
    "    if len(anomaly_indices) > 0:\n",
    "        plt.scatter(anomaly_indices, new_data.iloc[anomaly_indices], color='red', label='Anomalies')\n",
    "    plt.title('Time Series with Anomalies')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(errors, label='Reconstruction Error')\n",
    "    if isinstance(thresholds, np.ndarray):\n",
    "        plt.plot(thresholds, 'r--', label='Dynamic Threshold')\n",
    "    else:\n",
    "        plt.axhline(y=thresholds, color='r', linestyle='--', label=f'Threshold ({thresholds:.6f})')\n",
    "    \n",
    "    if len(anomaly_indices) > 0:\n",
    "        plt.scatter(anomaly_indices, errors[anomaly_indices], color='red')\n",
    "    \n",
    "    plt.title('Reconstruction Error with Threshold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('anomaly_detection_results.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Show top anomalies\n",
    "    top_anomalies = results[\"analysis\"][\"top_anomalies\"]\n",
    "    interpreter = results[\"analysis\"][\"interpreter\"]\n",
    "    \n",
    "    print(\"\\n=== Top 5 Detected Anomalies ===\")\n",
    "    for i, anomaly in enumerate(top_anomalies):\n",
    "        print(f\"Anomaly #{i+1}:\")\n",
    "        print(f\"  Index: {anomaly['index']}\")\n",
    "        if 'timestamp' in anomaly:\n",
    "            print(f\"  Timestamp: {anomaly['timestamp']}\")\n",
    "        print(f\"  Error: {anomaly['error']:.6f}\")\n",
    "        print(f\"  Threshold: {anomaly['threshold']:.6f}\")\n",
    "        print(f\"  Error/Threshold Ratio: {anomaly['error_ratio']:.4f}\")\n",
    "        \n",
    "        # Visualize the anomaly\n",
    "        interpreter.plot_reconstruction_comparison(anomaly['index'])\n",
    "        plt.savefig(f'anomaly_{i+1}_reconstruction.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        interpreter.visualize_contribution_heatmap(anomaly['index'])\n",
    "        plt.savefig(f'anomaly_{i+1}_heatmap.png', dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    # 3. Future predictions visualization if available\n",
    "    if \"predictions\" in results:\n",
    "        predictions = results[\"predictions\"][\"values\"]\n",
    "        horizon = results[\"predictions\"][\"horizon\"]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Plot original data\n",
    "        plt.plot(range(len(new_data)), new_data, label='Historical Data')\n",
    "        \n",
    "        # Plot predictions\n",
    "        pred_indices = range(len(new_data), len(new_data) + len(predictions))\n",
    "        plt.plot(pred_indices, predictions, 'g--', label='Predictions')\n",
    "        \n",
    "        plt.title('Time Series Predictions')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.savefig('predictions.png', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "# Main function to demonstrate the integrated system\n",
    "def main():\n",
    "    # Load all models\n",
    "    models = load_all_models()\n",
    "    \n",
    "    # Load a test dataset\n",
    "    filepath = 'data/machine_temperature_system_failure.csv'\n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    # Take a portion of the data for demonstration\n",
    "    test_data = df[['value']].iloc[-1000:]\n",
    "    \n",
    "    # Analyze the time series\n",
    "    results = analyze_time_series(test_data, models, device=device)\n",
    "    \n",
    "    # Visualize the results\n",
    "    visualize_integrated_results(test_data, results)\n",
    "    \n",
    "    print(\"\\nIntegrated analysis completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
